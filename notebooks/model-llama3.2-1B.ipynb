{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3385b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8013596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a16d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d177168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/third_party/models/Llama3.2-1B'...\n",
      "remote: Enumerating objects: 76, done.\u001b[K\n",
      "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 76 (delta 33), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (76/76), 2.27 MiB | 6.48 MiB/s, done.\n",
      "\u001b[33mhint: The '/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/.git/modules/third_party/models/Llama3.2-1B/hooks/post-checkout' hook was ignored because it's not set as executable.\u001b[m\n",
      "\u001b[33mhint: You can disable this warning with `git config set advice.ignoredHook false`.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git submodule add https://huggingface.co/meta-llama/Llama-3.2-1B  ./third_party/models/Llama3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8127d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing third_party/models/Llama3.2-1B/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile third_party/models/Llama3.2-1B/config.yaml\n",
    "\n",
    "base:\n",
    "  model_class: llama3_2\n",
    "  checkpoint: original/consolidated.00.pth\n",
    "  params: original/params.json\n",
    "  metadata: '{\"get_bos_id\":128000, \"get_eos_ids\":[128009, 128001]}'\n",
    "model:\n",
    "  use_kv_cache: True\n",
    "  use_sdpa_with_kv_cache: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/third_party/models/Llama3.2-1B\n",
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W1020 11:45:03.335000 19529 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/.venv/lib/python3.12/site-packages/executorch/exir/dialects/edge/_ops.py:9: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "I tokenizers:regex.cpp:27] Registering override fallback regex\n",
      "[2025-10-20 11:45:07,059][root][INFO] - Applying quantizers: []\n",
      "[2025-10-20 11:45:08,553][root][INFO] - Checkpoint dtype: torch.bfloat16\n",
      "[2025-10-20 11:45:08,553][root][INFO] - Replacing KVCache with CustomKVCache. This modifies the model in place.\n",
      "[2025-10-20 11:45:08,751][root][INFO] - Looking for libcustom_ops_aot_lib.so in /Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/.venv/lib/python3.12/site-packages/executorch/extension/llm/custom_ops\n",
      "[2025-10-20 11:45:08,752][root][INFO] - Loading custom ops library: /Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/.venv/lib/python3.12/site-packages/executorch/extension/llm/custom_ops/libcustom_ops_aot_lib.dylib\n",
      "[2025-10-20 11:45:08,864][root][INFO] - Model after source transforms: Transformer(\n",
      "  (tok_embeddings): Embedding(128256, 2048)\n",
      "  (layers): ModuleList(\n",
      "    (0-15): 16 x TransformerBlock(\n",
      "      (attention): AttentionMHA(\n",
      "        (wq): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (wk): Linear(in_features=2048, out_features=512, bias=False)\n",
      "        (wv): Linear(in_features=2048, out_features=512, bias=False)\n",
      "        (wo): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (rope): Rope(\n",
      "          (apply_rotary_emb): RotaryEmbedding()\n",
      "        )\n",
      "        (kv_cache): CustomKVCache()\n",
      "        (SDPA): SDPACustom()\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (w1): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "        (w2): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "        (w3): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "      )\n",
      "      (attention_norm): RMSNorm()\n",
      "      (ffn_norm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (rope): Rope(\n",
      "    (apply_rotary_emb): RotaryEmbedding()\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (output): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n",
      "[2025-10-20 11:45:08,864][root][INFO] - Exporting with:\n",
      "[2025-10-20 11:45:08,866][root][INFO] - inputs: (tensor([[2, 3, 4]]), {'input_pos': tensor([0])})\n",
      "[2025-10-20 11:45:08,866][root][INFO] - kwargs: None\n",
      "[2025-10-20 11:45:08,866][root][INFO] - dynamic shapes: ({1: Dim('token_dim', min=0, max=128)}, {'input_pos': {0: 1}})\n",
      "[2025-10-20 11:45:12,314][root][INFO] - Running canonical pass: RemoveRedundantTransposes\n",
      "[2025-10-20 11:45:12,342][root][INFO] - Using pt2e [] to quantizing the model...\n",
      "[2025-10-20 11:45:12,342][root][INFO] - No quantizer provided, passing...\n",
      "[2025-10-20 11:45:27,416][root][INFO] - Lowering model using following partitioner(s): \n",
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/.venv/lib/python3.12/site-packages/executorch/exir/emit/_emitter.py:1593: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized, unless a pass which sets meta[\"et_init_buffer\"] to True such as InitializedMutableBufferPass is run.\n",
      "  warnings.warn(\n",
      "[2025-10-20 11:45:34,216][root][INFO] - Required memory for activation in bytes: [0, 23101440]\n",
      "[2025-10-20 11:45:34,927][root][INFO] - Saved exported program to ./llama3_2.pte\n",
      "/Users/fmilo/workspace/sandbox/2025-oct-20-hackathon-qualcomm/third_party\n"
     ]
    }
   ],
   "source": [
    "current_path=!pwd\n",
    "%cd ./third_party/models/Llama3.2-1B/\n",
    "try:\n",
    "    import sys\n",
    "\n",
    "    !{sys.executable} -m executorch.extension.llm.export.export_llm --config config.yaml \n",
    "finally:\n",
    "    %cd ${current_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ed030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./third_party/models/Llama3.2-1B/llama3_2.pte\n"
     ]
    }
   ],
   "source": [
    "!ls ./third_party/models/Llama3.2-1B/*.pte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1bc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-oct-20-hackathon-qualcomm (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
